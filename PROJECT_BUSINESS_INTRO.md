# 黑科易购项目业务介绍与技术实践

## 1. 自我介绍

### 1.1 简洁版（面试用）
我叫张开源，黑龙江科技大学数据科学与大数据技术专业26届应届生，应聘Java后端工程师。

**核心优势**：
- 获奖经历：蓝桥杯省二等奖、中国大学生计算机设计大奖二等奖、连续两年国家励志奖学金
- 项目经验：参与智股通股票微服务项目（负责登录认证、股票数据爬虫与K线图展示）和云创商城电商项目（负责商品、订单、营销、权限模块）
- 技术栈：Spring Boot、Spring Cloud、MySQL、Redis、Python爬虫（Scrapy、BeautifulSoup）
- 在校表现：曾任校科协宣传部部长（每月4篇公众号推送）、班级科创委员

### 1.2 详细版

#### 1.2.1 基本信息
- 姓名：张开源
- 专业：数据科学与大数据技术
- 学校：黑龙江科技大学
- 届别：2026届应届毕业生
- 应聘岗位：Java后端工程师/开发岗

#### 1.2.2 实习与获奖经历
- **实习经验**：2025年6月获得扎实的实习经验，深度参与项目开发，累积了丰富的实战经验和问题解决能力
- **获奖情况**：
  - 第十五届蓝桥杯省二等奖
  - 第十八届中国大学生计算机设计大奖二等奖
  - 连续两年获得国家励志奖学金
  - 多项校级奖项
- **竞赛参与**：积极参加互联网+、蓝桥杯挑战赛等项目竞赛，提升技术学习能力、交流能力和团队协作能力

#### 1.2.3 在校职务
- **大学生科技协会宣传部部长**：负责公众号运营，每月推送4篇优质文章
- **班级课科创委员**：及时分享班级最新竞赛消息，协助同学参与各类科技活动

## 2. 项目经验

### 2.1 智股通股票项目（微服务架构）
- **项目描述**：股票数据分析与交易模拟平台
- **团队构成**：1名前端 + 3名后端
- **负责模块**：
  - 用户登录认证系统
  - 股票数据导出功能
  - 股票K线图数据处理与展示
  - **股票数据爬虫**：使用Python Scrapy框架开发爬虫，从财经网站采集实时股票数据，包括价格、成交量、K线图数据等
  - 数据清洗与结构化处理，将采集的数据存储到MySQL数据库
- **技术栈**：Spring Boot、Spring Cloud、MySQL、Redis、Kafka、Python、Scrapy、BeautifulSoup

### 2.2 云创商城电商项目（微服务架构）
- **项目描述**：完整的电商平台，包含商品、订单、营销、权限等核心模块
- **团队构成**：5人团队（实验室老师指导）
- **负责模块**：
  - **商品模块**：商品管理、添加编辑商品、商品分类管理、品牌管理
  - **订单模块**：订单管理、查看订单、订单发货、订单跟踪、退换货处理
  - **营销模块**：秒杀活动管理、优惠券管理、人气推荐、广告管理
  - **权限模块**：用户管理、角色管理、菜单管理、资源管理
- **技术栈**：Spring Boot、Spring Cloud、Nacos、MySQL、Redis、Elasticsearch、RabbitMQ

### 2.3 黑科易购项目（当前项目）
- **项目描述**：基于微服务架构的综合性商城系统
- **技术栈**：Spring Boot、Spring Cloud、Nacos、MySQL、Redis、Elasticsearch（可选）、RabbitMQ（可选）
- **部署环境**：VMware Workstation 17 + CentOS 7
- **Trae CN应用**：使用Trae CN AI开发工具辅助项目部署文档编写与优化

## 3. Trae CN技术实践与业务价值

### 3.1 Trae CN在项目中的应用场景

#### 3.1.1 部署文档自动化生成
- **业务需求**：需要一份详细的部署文档，指导团队成员快速部署项目环境
- **技术实践**：
  - 使用Trae CN分析现有项目结构和依赖关系
  - 结合VMware Workstation 17 + CentOS 7环境，自动生成针对性部署步骤
  - 生成的文档包含虚拟机配置、系统安装、软件环境搭建、项目部署等完整流程
- **业务价值**：
  - 减少手动编写文档的时间成本，提高文档准确性
  - 确保所有团队成员使用统一的部署标准
  - 降低新成员的学习曲线，快速融入项目

#### 3.1.2 代码智能辅助
- **业务需求**：提高代码编写效率，减少重复劳动，确保代码质量
- **技术实践**：
  - 使用Trae CN的代码补全功能，快速生成常用代码片段
  - 利用AI代码审查功能，提前发现潜在的代码问题
  - 借助Trae CN的重构建议，优化现有代码结构
- **业务价值**：
  - 提高开发效率，缩短项目交付周期
  - 提升代码质量，减少线上bug
  - 促进团队代码风格统一，便于维护

#### 3.1.3 技术问题诊断与解决
- **业务需求**：快速定位和解决开发过程中遇到的技术问题
- **技术实践**：
  - 使用Trae CN分析错误日志，提供可能的解决方案
  - 借助AI知识库，获取相关技术栈的最佳实践
  - 利用Trae CN的调试建议，加速问题排查过程
- **业务价值**：
  - 减少问题排查时间，提高开发效率
  - 积累技术解决方案，形成团队知识库
  - 降低对资深开发者的依赖，提升团队整体解决问题的能力

### 3.2 黑科易购项目部署实践（基于Trae CN）

#### 3.2.1 环境准备阶段
- **虚拟机配置**：使用Trae CN生成VMware Workstation 17虚拟机配置指南，包括内存、CPU、磁盘等参数建议
- **系统安装**：结合CentOS 7镜像，生成详细的系统安装步骤，包括分区方案、网络配置等
- **系统初始化**：自动生成系统初始化脚本，包括防火墙关闭、SELinux配置、系统更新等

#### 3.2.2 软件环境搭建
- **依赖管理**：使用Trae CN分析项目依赖，生成JDK、Maven、Node.js、MySQL、Redis、Nacos等软件的安装命令和配置步骤
- **服务配置**：自动生成各服务的配置文件模板，包括数据库连接、Redis配置、Nacos注册中心配置等
- **服务启动**：生成服务启动脚本和顺序建议，确保服务间依赖关系正确

#### 3.2.3 项目部署与验证
- **后端部署**：生成后端服务的构建命令和启动脚本，包括多模块服务的启动顺序
- **前端部署**：生成前端项目的依赖安装、构建命令和Nginx配置文件
- **部署验证**：提供服务验证方法，包括Nacos服务注册检查、Swagger文档访问、前端页面功能测试等

### 3.3 Trae CN带来的业务价值

#### 3.3.1 提高开发效率
- 自动化文档生成，减少手动编写时间
- 智能代码补全，加速代码编写过程
- 快速问题诊断，减少调试时间

#### 3.3.2 提升代码质量
- AI代码审查，提前发现潜在问题
- 重构建议，优化代码结构
- 遵循最佳实践，确保代码规范

#### 3.3.3 降低技术门槛
- 详细的部署文档，便于新成员快速上手
- 技术问题解决方案，减少对资深开发者的依赖
- 标准化的配置模板，确保环境一致性

#### 3.3.4 促进团队协作
- 统一的部署标准，减少环境差异导致的问题
- 共享的技术知识库，便于团队成员学习和交流
- 自动化的流程文档，提高团队协作效率

## 4. 技术栈与技能总结

### 4.1 核心技术栈
- **后端框架**：Spring Boot、Spring Cloud、Spring Security
- **微服务组件**：Nacos、Feign、Gateway、Sentinel
- **数据库**：MySQL、Redis、Elasticsearch
- **消息队列**：RabbitMQ、Kafka
- **开发工具**：IntelliJ IDEA、Trae CN AI开发工具、Git
- **部署环境**：Linux（CentOS 7）、Docker、VMware

### 4.2 核心技能
- 微服务架构设计与实现
- 分布式系统开发与调试
- 数据库设计与优化
- 缓存策略设计与实现
- 消息队列应用与优化
- 系统性能监控与调优
- 网络爬虫开发与数据采集
  - 熟悉Python爬虫框架（Scrapy、BeautifulSoup、Selenium）
  - 具备反爬虫策略应对经验（代理IP、验证码识别、请求频率控制）
  - 数据清洗与结构化处理能力
- AI开发工具的熟练应用

## 5. 职业规划与发展方向

### 5.1 短期目标（1-2年）
- 深入学习微服务架构，成为资深Java后端工程师
- 掌握更多AI开发工具的应用场景，提高开发效率
- 参与大型分布式系统的设计与开发

### 5.2 长期目标（3-5年）
- 成长为技术负责人，带领团队完成复杂项目
- 深入研究AI辅助开发技术，推动团队开发效率提升
- 关注行业技术趋势，持续学习和创新

## 6. 总结

作为一名26届应届毕业生，我具备扎实的Java后端开发基础，丰富的项目经验，以及较强的团队协作能力。通过使用Trae CN等AI开发工具，我能够提高开发效率，提升代码质量，快速解决技术问题。我相信，在未来的工作中，我将继续努力学习，不断提升自己的技术能力，为团队和公司创造更大的价值。

感谢您的耐心阅读！